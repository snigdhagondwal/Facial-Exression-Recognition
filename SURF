from sklearn.decomposition import PCA
tf.reset_default_graph()

pca = PCA(n_components=2)
surf = cv2.xfeatures2d.SURF_create()

init=0
response=[]
feature_mat = []
for j in ["Afraid","Anger","Disgusted","Happy","Neutral","sad","Surprise"]:
        files = glob.glob("/content/drive/My Drive/Emotion Fera Deep/Fera2013/"+j+"/*.JPG")
        for i in files:
                fr=cv2.imread(i)
                gray =cv2.cvtColor(fr, cv2.COLOR_BGR2GRAY)
                gray = cv2.resize(gray,(128,128))
                faces = facec.detectMultiScale(gray, 1.3, 5)
                for (x, y, w, h) in faces:
                        fc = gray[y:y+h, x:x+w]
                        cv2.rectangle(fr, (x, y), (x + w, y + h), (0, 0, 255), 2)
                #cv2_imshow(fc)
                #cv2.waitKey(10)
                r = cv2.resize(fc,(1152,1152))     
                kp, descritors = surf.detectAndCompute(r,None)
                img2 = cv2.drawKeypoints(r,kp,None,(255,0,0),4)
                img2 = cv2.cvtColor(img2, cv2.COLOR_BGR2GRAY)
                #cv2_imshow(img2)
                #cv2.waitKey(10)
                x = pca.fit_transform(img2)   
                feature_mat.append(x)  
                response.append(init)
        init=init+1

# create BFMatcher object
bf = cv2.BFMatcher(cv2.NORM_L1,crossCheck=False)
predicted = []
for i in range(0,len(feature_mat)):
  match=[]
  meas = feature_mat.copy()
  group = response.copy()
  sample= feature_mat[i]
  meas.pop(i)
  group.pop(i)
  for j in meas:
    matches = bf.knnMatch(sample,j,2)
    # Apply ratio test
    good = []
    for m,n in matches:
      if m.distance < 0.85*n.distance:
        good.append([m])
    match.append(len(good))
  res = group[match.index(max(match))] 
  predicted.append(res)
accSURF = accuracy_score(predicted,response)*100
print("SURF Accuracy")
print(accSURF)
